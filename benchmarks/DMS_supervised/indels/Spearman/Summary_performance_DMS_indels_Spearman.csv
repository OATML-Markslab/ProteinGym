Model_rank,Model_name,Model type,Average_Spearman,Bootstrap_standard_error_Spearman,Average_Spearman_fold_random_5,Function_Activity,Function_Binding,Function_Expression,Function_OrganismalFitness,Function_Stability,Low_MSA_depth,Medium_MSA_depth,High_MSA_depth,Taxa_Human,Taxa_Other_Eukaryote,Taxa_Prokaryote,Taxa_Virus,References,Model details
1,ESM-1v Embeddings,Embedding,0.752,0.0,0.752,0.705,N/A,0.728,0.718,0.856,0.843,0.747,0.838,0.821,0.842,0.848,0.835,"[1] Original model: <a href='https://proceedings.neurips.cc/paper/2021/hash/f51338d736f95dd42427296047067694-Abstract.html'>Meier, J., Rao, R., Verkuil, R., Liu, J., Sercu, T., & Rives, A. (2021). Language models enable zero-shot prediction of the effects of mutations on protein function. NeurIPS.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ESM-1v Embeddings
2,Tranception Embeddings,Embedding,0.735,0.007,0.735,0.674,N/A,0.753,0.716,0.797,0.797,0.745,0.774,0.767,0.789,0.8,0.785,"[1] Original model: <a href='https://proceedings.mlr.press/v162/notin22a.html'>Notin, P., Dias, M., Frazer, J., Marchena-Hurtado, J., Gomez, A.N., Marks, D.S., & Gal, Y. (2022). Tranception: Protein Fitness Prediction with Autoregressive Transformers and Inference-time Retrieval. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",Tranception Embeddings
3,MSA Transformer Embeddings,Embedding,0.689,0.004,0.689,0.661,N/A,0.614,0.71,0.769,0.764,0.723,0.752,0.733,0.765,0.776,0.754,"[1] Original model: <a href='http://proceedings.mlr.press/v139/rao21a.html'>Rao, R., Liu, J., Verkuil, R., Meier, J., Canny, J.F., Abbeel, P., Sercu, T., & Rives, A. (2021). MSA Transformer. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",MSA Transformer Embeddings
